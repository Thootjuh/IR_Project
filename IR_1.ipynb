{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S2gN4tdArEe"
      },
      "source": [
        "Thomas Rhemrev (s1045660), Boudewijn van Gils (s1045276), Harm Jacobs (s1019253)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrlT4gwqz10b"
      },
      "source": [
        "# 1 Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kf-Ik9vA35y"
      },
      "source": [
        "### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E3zYWdtZAqCI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import ast\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZIpHKYmCWmX"
      },
      "source": [
        "### 1.2 Importing the files\n",
        "This cell only needs to be run once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32xhAlxWDONX",
        "outputId": "41eb0948-2a05-494a-a36e-f9328a16f518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "collection.tsv is already loaded\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/collection.tsv'\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    # Download all the files if collection.tsv is in content\n",
        "    !wget https://transfer.sh/eyMUhyJHnd/queries.dev.small.tsv -P /content/\n",
        "    !wget https://transfer.sh/MLJmo5hG1Q/collection.tsv -P /content/\n",
        "    !wget https://transfer.sh/8J3xKmO7Qb/qrels.dev.small.tsv -P /content/\n",
        "\n",
        "    !wget https://transfer.sh/P2pjXPrj1L/queries.dev.tsv -P /content/\n",
        "    !wget https://transfer.sh/vF2elQ2avA/queries.eval.tsv -P /content/\n",
        "    !wget https://transfer.sh/EFVqqUL32r/queries.train.tsv -P /content/\n",
        "    !wget https://transfer.sh/54I2wsGupJ/qrels.train.tsv -P /content/\n",
        "    !wget https://transfer.sh/yESAJ7R4wy/queries.eval.small.tsv -P /content/\n",
        "\n",
        "else:\n",
        "    print(\"collection.tsv is already loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cnuxtHz63c"
      },
      "source": [
        "### 1.3 Creating the dictionaries\n",
        "\n",
        "Load the collection, queries and qrel data libraries are created from the tsv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rnTw5wCd0n25"
      },
      "outputs": [],
      "source": [
        "queries_dict = {}\n",
        "collection_dict = {}\n",
        "qrels_dict = {}\n",
        "\n",
        "def load_data_tsv(filename, process_row):\n",
        "    #opens a tsv file and applies the process_row function to every row\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=\"\\t\")\n",
        "        for row in csv_reader:\n",
        "            process_row(row)\n",
        "\n",
        "def process_qrels_row(row):\n",
        "    if int(row[0]) not in qrels_dict:\n",
        "            qrels_dict[int(row[0])] = [int(row[2])]\n",
        "    else: qrels_dict[int(row[0])].append(int(row[2]))\n",
        "\n",
        "def process_queries_row(row):\n",
        "    queries_dict[int(row[0])] = row[1]\n",
        "\n",
        "def process_collection_row(row):\n",
        "    collection_dict[int(row[0])] = row[1]\n",
        "\n",
        "keep = [1578304, 1578305, 1578306, 1578307, 1578311, 1578312, 1578313, 739802, 739803, 739804, 739805, 739806, 739807, 739811, 2754977, 2754978, 2754979, 2754980, 2754981, 2754983, 2754984, \n",
        "        3008361, 3008362, 3008363, 3008364, 3008366, 3008367, 3008370, 2180634, 3614173, 4152760, 2302160, 4152761, 2180637, 4152762]\n",
        "   \n",
        "def process_collection_row_smaller(row):\n",
        "    if row[0].endswith('1') or int(row[0]) in keep:\n",
        "        collection_dict[int(row[0])] = row[1]\n",
        "\n",
        "\n",
        "load_data_tsv(\"collectionandqueries/queries.dev.small.tsv\", process_queries_row)\n",
        "load_data_tsv(\"collectionandqueries/collection.tsv\", process_collection_row)\n",
        "load_data_tsv(\"collectionandqueries/qrels.dev.small.tsv\", process_qrels_row)\n",
        "\n",
        "# queries_dict[0] = \"apple phone\"\n",
        "# collection_dict[0] = \"phone samsung phone\"\n",
        "# collection_dict[1] = \"Apple and a Pear\"\n",
        "# collection_dict[2] = \"Apple phone\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We remove all stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "STOPWORDS = set(['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with'])\n",
        "\n",
        "def process(text):\n",
        "    terms = []\n",
        "    # Remove special characters\n",
        "    chars = ['\\'', '.', ':', ',', '!', '?', '(', ')']\n",
        "    for ch in chars:\n",
        "        if ch in text:\n",
        "            text = text.replace(ch, ' ')\n",
        "\n",
        "    # Lowercasing and stopword removal\n",
        "    for term in text.split():\n",
        "        term = term.lower()\n",
        "        if term not in STOPWORDS:\n",
        "            terms.append(term)\n",
        "    return terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create the indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 7663562/8841823 [09:01<01:13, 16105.21it/s]"
          ]
        }
      ],
      "source": [
        "index = {}\n",
        "\n",
        "for document_id, content in tqdm(collection_dict.items()):\n",
        "    processed_terms = process(content)\n",
        "    collection = collections.Counter(processed_terms)\n",
        "    for key, value in collection.items():\n",
        "        if key in index:\n",
        "            index[key][document_id] = value\n",
        "        else:\n",
        "            index[key] = {document_id: value}\n",
        "\n",
        "counter = 0\n",
        "for key, value in index.items():\n",
        "    print(key, value)\n",
        "    if counter > 10:\n",
        "        break\n",
        "    counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmIrO9ha04w3"
      },
      "source": [
        "# 2 Exploring the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzMjfj_TUrb2"
      },
      "source": [
        "### 2.1 Printing the heads of the dictionaries\n",
        "Just to check whether they load correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHNO181xROUQ",
        "outputId": "75a38826-4227-4d90-fbf6-c3b96375045e"
      },
      "outputs": [],
      "source": [
        "def print_dict_head(d, num_items=5):\n",
        "    count = 0\n",
        "    for key, value in d.items():\n",
        "        if count < num_items:\n",
        "            print(key, \":\", value)\n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "print(len(queries_dict))\n",
        "print(\"QUERIES:\")\n",
        "print_dict_head(queries_dict)\n",
        "print(\"COLLECTION:\")\n",
        "print_dict_head(collection_dict)\n",
        "print(\"QRELS:\")\n",
        "print_dict_head(qrels_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R1nVS3rU280"
      },
      "source": [
        "### 2.2 Finding queries with multiple relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpLE3z42U2A_",
        "outputId": "494c9b8a-3db7-4bfa-be9d-c1b140d5130a"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "biggest = []\n",
        "for key, value in qrels_dict.items():\n",
        "    if (len(value)> max):\n",
        "        biggest = [key]\n",
        "        max = len(value)\n",
        "    elif (len(value) == max):\n",
        "        biggest.append(key)\n",
        "print(max)\n",
        "print(biggest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDmL5npgVlHM"
      },
      "source": [
        "### 3 Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def idf(term, n_documents):\n",
        "    n = len(index[term])\n",
        "    return math.log((n_documents-n+0.5)/(n+0.5)+1)\n",
        "\n",
        "def idf2(term, n_documents):\n",
        "    n = len(index[term])\n",
        "    return math.log((n_documents+1)/(n+1))\n",
        "\n",
        "def idfProb(term, n_documents):\n",
        "    n = len(index[term])\n",
        "    return math.log((n_documents-n+0.5)/(n+0.5)+1)*(1-(n/n_documents))\n",
        "\n",
        "def idfProb2(term, n_documents):\n",
        "    n = len(index[term])\n",
        "    return math.log((n_documents+1)/(n+1))*(1-(n/n_documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bm25(query_id, doc_id, k1, b, n_documents, avgdl):\n",
        "    sum = 0\n",
        "    query = queries_dict[query_id]\n",
        "    for q in query.split(' '):\n",
        "        if(q in index):\n",
        "            idf_score = index[q]['idf']\n",
        "            if(doc_id in index[q]):\n",
        "                f = index[q][doc_id]\n",
        "                sum += idf_score * ((f * (k1+1))/(f + k1 *(1 - b + b*(len(collection_dict[doc_id])/avgdl))))\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding IDF to Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for term in tqdm(index.keys()):\n",
        "    idf_val = idfProb2(term, len(collection_dict))\n",
        "    index[term]['idf'] = idf_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting important parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_documents = len(collection_dict)\n",
        "avgdl = np.mean([len(text.split(' ')) for text in collection_dict.values()])\n",
        "k1 = 1.2\n",
        "b = 0.75\n",
        "\n",
        "print(avgdl)\n",
        "print(n_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the ranking function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#qq is the query ID\n",
        "qq = 504335\n",
        "def rank(query_id, count, k1, b, n_documents, avgdl):\n",
        "    scores = []\n",
        "    for doc_id in collection_dict.keys():\n",
        "        score = bm25(query_id, doc_id, k1, b, n_documents, avgdl)\n",
        "        scores.append((doc_id, score))\n",
        "        \n",
        "    ranked_documents = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    return ranked_documents[:count]\n",
        "\n",
        "\n",
        "\n",
        "ranking = rank(qq, n_documents, k1, b, n_documents, avgdl)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.1 Exploring the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "relevant = qrels_dict[qq]\n",
        "def findRelevant(relevant, ranking):\n",
        "    found = []\n",
        "    counter = 0\n",
        "    for doc in ranking:\n",
        "        if doc[0] in relevant:\n",
        "            found.append((counter, doc))\n",
        "        if len(found) == len(relevant):\n",
        "            return found\n",
        "        counter+=1\n",
        "\n",
        "\n",
        "print(findRelevant(relevant, ranking))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(ranking[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(queries_dict[qq])\n",
        "print(\"relevant\")\n",
        "for i in relevant:\n",
        "    print(collection_dict[i])\n",
        "\n",
        "print(\"top 10\")\n",
        "for i in ranking[:10]:\n",
        "    print(collection_dict[i[0]])\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4 Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define functions to calculate recall and reciprocal rank for each query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_relevancy_labels(query, top_results):\n",
        "  relevancy_labels = []\n",
        "  for r in top_results:\n",
        "    if r[0] in qrels_dict[query]:\n",
        "      relevancy_labels.append(1)\n",
        "    else:\n",
        "      relevancy_labels.append(0)\n",
        "  return relevancy_labels\n",
        "\n",
        "def recall(query, query_relevancy_labels):\n",
        "    if sum(query_relevancy_labels) == 0:\n",
        "      return 0\n",
        "    return sum(query_relevancy_labels)/len(qrels_dict[query])\n",
        "  \n",
        "def reciprocalRank(relevant, ranking, k):\n",
        "    counter = 0\n",
        "    for doc in ranking:\n",
        "      counter+=1\n",
        "      if doc[0] in relevant or counter == k:\n",
        "        return 1/counter\n",
        "        \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the recall and reciprocal rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "query = 457622\n",
        "ranking = rank(query, 1000, k1, b, n_documents, avgdl)\n",
        "lab = get_relevancy_labels(query, ranking)\n",
        "print(recall(query, lab))\n",
        "print(reciprocalRank(qrels_dict[query], ranking, 10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculating the average recall en MMR over n_queries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recalls = []\n",
        "rrs = []\n",
        "counter = 0\n",
        "n_queries = 10\n",
        "queries = []\n",
        "for query in queries_dict.keys():\n",
        "    queries.append(query)\n",
        "    counter+=1\n",
        "    if counter == n_queries:\n",
        "        break\n",
        "    \n",
        "for query in tqdm(queries):\n",
        "    ranking = rank(query, 1000, k1, b, n_documents, avgdl)\n",
        "    lab = get_relevancy_labels(query, ranking)\n",
        "    recalls.append(recall(query, lab))\n",
        "    rrs.append(reciprocalRank(qrels_dict[query], ranking, 10))\n",
        "\n",
        "\n",
        "model_recall = np.mean(np.array(recalls))\n",
        "mrr = np.mean(np.array(rrs))    \n",
        "\n",
        "print(\"recall@1000 = \", model_recall, \"mrr@10 = \", mrr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
